{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from config import START,END,INTERVAL,INIT_H,END_H,SATELLITE,PRODUCT,CHANNEL,PATH\n",
    "import s3fs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from datetime import *\n",
    "import pathlib\n",
    "\n",
    "import netCDF4\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_list():\n",
    "    days = pd.date_range(start=START, end=END, freq=INTERVAL)\n",
    "    hours = pd.date_range(INIT_H,END_H, freq=INTERVAL).strftime('%H:%M:%S')\n",
    "\n",
    "    data_range = []\n",
    "    for d in range(len(days)):\n",
    "        for m in range(len(hours)):\n",
    "            if days[d].strftime('%H:%M:%S') == hours[m]:\n",
    "                data_range.append(days[d])\n",
    "    return data_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aws_file_list(list_of_files):\n",
    "\n",
    "    DownloadList = pd.DataFrame()  \n",
    "    timestamp = []\n",
    "    fileslist = []\n",
    "    stringList = []\n",
    "    \n",
    "    for i in list_of_files:\n",
    "        ListFiles = np.array(aws.ls(server+i.strftime('%Y/%j/%H')))\n",
    "        stringList.append(i.strftime('%Y%j%H%M'))\n",
    "        timestamp.append(i.strftime('%Y/%m/%d %H:%M'))\n",
    "        \n",
    "        for file in ListFiles: \n",
    "            if file.find('M3C'+str(CHANNEL)) >= 1:\n",
    "                fileslist.append(str(file))\n",
    "                \n",
    "            elif file.find('M6C'+str(CHANNEL)) >= 1:\n",
    "                fileslist.append(str(file))\n",
    "                \n",
    "                \n",
    "    list_ = pd.DataFrame({'url':fileslist})\n",
    "    list_ = list_.drop_duplicates()\n",
    "\n",
    "    regstr = '|'.join(stringList)\n",
    "    list_['strings'] = list_['url'].str.upper().str.contains(regstr)\n",
    "\n",
    "    DownloadList = list_[list_.strings]\n",
    "    DownloadList = DownloadList.drop(['strings'], axis=1)\n",
    "    DownloadList['timestamp'] = timestamp\n",
    "    DownloadList['path'] = DownloadList['url'].str.replace(SATELLITE, PATH)\n",
    "    DownloadList['url'] = DownloadList['url'].str.replace(SATELLITE, 'https://'+SATELLITE+'.s3.amazonaws.com')\n",
    "    DownloadList['file'] = DownloadList.apply(lambda x: pathlib.Path(x.path).name, axis=1)\n",
    "    DownloadList['path'] = DownloadList.apply(lambda x: pathlib.Path(x.path).parent, axis=1)\n",
    "\n",
    "    return DownloadList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(list_of_files):\n",
    "\n",
    "    fils = len(list_of_files)\n",
    "    cnt = 0\n",
    "    \n",
    "    for i,row in list_of_files.iterrows():\n",
    "        print('File Counter',cnt+1,'/',fils)\n",
    "        print('Downloading...')\n",
    "\n",
    "        StartTime = datetime.now()\n",
    "        req = requests.get(row.url, stream = True)\n",
    "        total_size = int(req.headers['content-length'])\n",
    "        size = 0\n",
    "        \n",
    "        pathlib.Path(row.path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        with open(str(row.path)+'/'+str(row.file),'wb') as output:\n",
    "            for chunk in req.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    rec_size = output.write(chunk)\n",
    "                    size = rec_size + size\n",
    "                    print('{}\\t{:3.0f}%\\t{:.2f} min'.format(row.file,100.0*size/total_size, (datetime.now()-StartTime).seconds/60.0), end='\\r', flush=True)\n",
    "        print('\\n')\n",
    "        \n",
    "        ## Process\n",
    "        print('Processing...')\n",
    "        path_ = (str(row.path)+'/'+str(row.file))\n",
    "        open_netcdf(path_,row.file)\n",
    "        cnt +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_netcdf(path_,file):\n",
    "    ## Copy global atributes\n",
    "    dataset = netCDF4.Dataset(path_, 'a')\n",
    "    scale_factor = dataset.variables['CMI'].scale_factor\n",
    "    long_name = dataset.variables['CMI'].long_name\n",
    "    ## Atributes\n",
    "    naming_authority = dataset.naming_authority\n",
    "    \n",
    "    \n",
    "    ### Translate\n",
    "    print('Translating file...')\n",
    "    cmd1 = \"gdal_translate -q -a_srs\"\n",
    "    cmd2 = \" \\\"+proj=geos +a=6.37814e+06  +b=6.35675e+06 +lon_0=-75 +f=298.257 +h=35786023 +sweep=x\\\" \"\n",
    "    cmd3 = \"-a_scale \"+str(scale_factor)+\" -a_ullr -5434390.3880000000000 5434390.3880000000000 5434390.3880000000000 -5434390.3880000000000 HDF5:\"\n",
    "    cmd4 = \"\\\"./\"+str(path_)+\"\\\"\"\n",
    "    cmd5 = \"://CMI -a_nodata -1 -of netCDF temp/navigation.modified.nc\"\n",
    "    full_cmd = cmd1+cmd2+cmd3+cmd4+cmd5\n",
    "\n",
    "    os.environ['HDF5_USE_FILE_LOCKING']='FALSE'\n",
    "    os.system(full_cmd)\n",
    "    \n",
    "    ## Warp file\n",
    "    print('Warping file...')\n",
    "    cmd1_ = \"gdalwarp -q -multi \"\n",
    "    cmd2_ = \"-s_srs \\\"+proj=geos +a=6.37814e+06  +b=6.35675e+06 +lon_0=-75 +f=298.257 +h=35786023\\\" \"\n",
    "    cmd3_ = \"-nomd -te -75.0 -35.0 -33.0 7.0 -t_srs '+proj=latlong +datum=WGS84\\' \"\n",
    "    cmd4_ = \"./temp/navigation.modified.nc \"\n",
    "    cmd5_ = \"-of netCDF -co compress=DEFLATE -co FORMAT=NC4C -r near \"\n",
    "    cmd6_ = \"temp/\"+file\n",
    "    \n",
    "    full_cmd_ = (cmd1_+cmd2_+cmd3_+cmd4_+cmd5_+cmd6_)\n",
    "\n",
    "    os.system(full_cmd_)\n",
    "    ## Rename Band 1 to CMI\n",
    "    os.system(\"ncrename -h -O -v Band1,CMI temp/\"+str(file))\n",
    "    ## Rename longname\n",
    "    os.system(\"ncatted -O -a long_name,CMI,o,c,\\\"\"+str(long_name)+\"\\\" temp/\"+str(file))\n",
    "\n",
    "    ## Add Global atributes \n",
    "    os.system(\"ncatted -O -h -a naming_authority,global,o,c,\"+str(naming_authority)+\" temp/\"+str(file))\n",
    "    \n",
    "    ## Remove navigation file\n",
    "    os.system(\"rm -rf temp/navigation.modified.nc\")\n",
    "    dataset.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files = file_list()\n",
    "server = SATELLITE+'/'+PRODUCT+'/'    \n",
    "aws = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "lista = aws_file_list(list_of_files)\n",
    "# download_files(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
